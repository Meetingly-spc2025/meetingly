import os
import uuid
import shutil
from dotenv import load_dotenv
from openai import OpenAI
from pydub import AudioSegment
import ffmpeg
import tiktoken

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ìŒì„± â†’ wav ë³€í™˜
def convert_to_wav(input_path):
    tmp_dir = "tmp_audio"
    os.makedirs(tmp_dir, exist_ok=True)
    output_path = os.path.join(tmp_dir, f"{uuid.uuid4().hex[:8]}.wav")

    try:
        ffmpeg.input(input_path).output(
            output_path, format='wav', acodec='pcm_s16le', ac=1, ar='16000'
        ).overwrite_output().run(quiet=True)
        return output_path
    except ffmpeg.Error as e:
        raise RuntimeError(f"FFmpeg ë³€í™˜ ì‹¤íŒ¨: {e.stderr.decode()}")

# Whisper ë³€í™˜
def transcribe_audio(wav_path):
    if not os.path.exists(wav_path):
        raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {wav_path}")

    with open(wav_path, "rb") as f:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            language="ko"
        )
    return response.text

# í† í° ê³„ì‚°
def get_token_count(text, model="gpt-4"):
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

# ë‹¨ì¼ ìš”ì•½
def summarize_text(full_text):
    prompt = """
ë‹¤ìŒ {full_text}ì˜ ë‚´ìš©ì€ íšŒì˜ë¡ì…ë‹ˆë‹¤. íšŒì˜ ë‚´ìš©ì„ ì´ 3ë¬¸ë‹¨ìœ¼ë¡œ ë„ˆë¬´ ê¸¸ì§€ ì•Šë„ë¡ ìš”ì•½í•´ ì£¼ì„¸ìš”. 
- í•œ ë¬¸ë‹¨ë§ˆë‹¤ ë‘ ë²ˆì”© ì¤„ ë°”ê¿ˆì„ í•´ì£¼ê³ , ìš”ì•½ì˜ ë‚´ìš©ì€ ê°ì •ì„ ëº€ ì •ë³´ ìœ„ì£¼ë¡œ í•´ì£¼ì„¸ìš”. 
- ëŒ€ë¶€ë¶„ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´, ì¼ì— ëŒ€í•œ ë‚´ìš©ì´ ëŒ€ë¶€ë¶„ì„ì„ ì°¸ê³ í•´ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.

\n\n
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ë¡ ì „ë¬¸ ìš”ì•½ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# í•  ì¼ ì¶”ì¶œ
def extract_tasks(summary):
    prompt = f"""
    íšŒì˜ 3ë¬¸ë‹¨ ìš”ì•½:
    {summary}

    ë‹¤ìŒ ìš”ì•½ëœ íšŒì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ íšŒì˜ ì¢…ë£Œ í›„, í•´ì•¼ í•  ì‘ì—… ëª©ë¡ì„ í•­ëª©ë³„ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
    - ê° í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±.
    - ì¶œë ¥ì€ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
    - ë§Œì•½ ì¶”ì¶œí•  í•  ì¼ì´ ì—†ë‹¤ë©´ "í•  ì¼ì´ ì—†ìŒ"ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”.
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ì— ëŒ€í•œ í•  ì¼ ì¶”ì¶œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# ìµœì¢… íŒŒì´í”„ë¼ì¸
def run_pipeline(audio_path, char_limit=5000):
    print("[ğŸ”§] Whisper ì²˜ë¦¬ë¥¼ ìœ„í•´ wav ë³€í™˜ ì¤‘...")
    wav_path = convert_to_wav(audio_path)

    print("[ğŸ™ï¸] Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
    transcript = transcribe_audio(wav_path)

    total_chars = len(transcript)
    print(f"[ğŸ“] í…ìŠ¤íŠ¸ ê¸¸ì´: {total_chars}ì")

    summary = None
    tasks = None

    if total_chars > char_limit:
        print(f"[âš ï¸] ê¸€ì ìˆ˜ {total_chars}ì > {char_limit}ì â†’ ìš”ì•½ ë° í•  ì¼ ì¶”ì¶œ ìƒëµ")
    else:
        print("[ğŸ§ ] ìš”ì•½ ì¤‘...")
        summary = summarize_text(transcript)

        print("[ğŸ“] í•  ì¼ ì¶”ì¶œ ì¤‘...")
        tasks = extract_tasks(summary)

    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
    try:
        os.remove(audio_path)
        os.remove(wav_path)
        print("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"[âš ï¸] íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {e}")

    return {
        "transcript": transcript,
        "summary": summary,
        "tasks": tasks
    }
