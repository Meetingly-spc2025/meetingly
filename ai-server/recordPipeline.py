import os
import shutil
import ffmpeg
from openai import OpenAI
from dotenv import load_dotenv 

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# segment ë””ë ‰í† ë¦¬ ê²½ë¡œëŠ” roomId ë³„ë¡œ ì„¤ì •
SEGMENT_BASE_DIR = "segments"

# 1. ì˜¤ë””ì˜¤ ë¶„í• 
def split_audio(input_path: str, room_id: str, segment_length: int = 600):
    segment_dir = os.path.join(SEGMENT_BASE_DIR, room_id)
    os.makedirs(segment_dir, exist_ok=True)
    output_pattern = os.path.join(segment_dir, "part_%03d.m4a")
    try:
        ffmpeg.input(input_path).output(
            output_pattern,
            f="segment",
            segment_time=segment_length,
            c="aac",
            map="0",
            reset_timestamps=1
        ).run(overwrite_output=True)
        print(f"[ğŸ§] ì˜¤ë””ì˜¤ ë¶„í•  ì™„ë£Œ: {segment_dir}")
    except ffmpeg.Error as e:
        print("[âœ˜] ì˜¤ë””ì˜¤ ë¶„í•  ì‹¤íŒ¨:", e.stderr.decode())
    return segment_dir

# 2. Whisper ì „ì‚¬
def transcribe_audio(path: str) -> str:
    with open(path, "rb") as f:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            language="ko"
        )
        return response.text

# 3. í…ìŠ¤íŠ¸ chunk ë‚˜ëˆ„ê¸°
def chunk_text(text: str, max_chars: int = 3000) -> list:
    import textwrap
    return textwrap.wrap(text, max_chars)

# 4. 1ì°¨ ìš”ì•½
def summarize_chunk(chunk: str, index: int) -> str:
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ìš”ì•½ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": f"[ë¶€ë¶„ {index+1}] ì•„ë˜ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”:\n\n{chunk}"}
        ]
    )
    return response.choices[0].message.content.strip()

# 5. 2ì°¨ ìš”ì•½
def summarize_full_text(full_text: str) -> str:
    chunks = chunk_text(full_text)
    print(f"[ğŸ“š] í…ìŠ¤íŠ¸ {len(chunks)} ì¡°ê°ìœ¼ë¡œ ë¶„í• ë¨")

    summaries = []
    for i, chunk in enumerate(chunks):
        print(f"[ğŸ“] 1ì°¨ ìš”ì•½ ì¤‘: {i+1}/{len(chunks)}")
        summaries.append(summarize_chunk(chunk, i))

    combined = "\n".join(summaries)

    print("[ğŸ§ ] 2ì°¨ ìš”ì•½ ì¤‘...")
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ìš”ì•½ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": f"ë‹¤ìŒ ë‚´ìš©ì„ 3ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\n\n{combined}"}
        ]
    )
    return response.choices[0].message.content.strip()


# ì£¼ìš” ë…¼ì˜ ì‚¬í•­ ì¶”ì¶œ
def summaries_discussion(summary):
    prompt = f"""
ë‹¤ìŒ ìš”ì•½ëœ íšŒì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì£¼ìš” ë…¼ì˜ ì£¼ì œì— ëŒ€í•´ì„œ 20ê¸€ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
ë…¼ì˜ ì£¼ì œê°€ ì—¬ëŸ¬ê°€ì§€ë¼ë©´ í•˜ë‚˜ì˜ ë…¼ì˜ ì£¼ì œë§ˆë‹¤ \n\n ì„ ë„£ì–´ì„œ êµ¬ë¶„í•´ì£¼ì„¸ìš”.

íšŒì˜ 3ë¬¸ë‹¨ ìš”ì•½:
{summary}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ìš” ë…¼ì˜ ì‚¬í•­ì„ ì •ë¦¬í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()


# 6. í•  ì¼ ì¶”ì¶œ
def extract_tasks(summary: str) -> str:
    prompt = f"""
ë‹¤ìŒ ìš”ì•½ëœ íšŒì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•  ì‘ì—… ëª©ë¡ì„ í•­ëª©ë³„ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
- ê° í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±.
- ì¶œë ¥ì€ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
- ë§Œì•½ ì¶”ì¶œí•  í•  ì¼ì´ ì—†ë‹¤ë©´ "false"ë¥¼ ë°˜í™˜í•´ì£¼ì„¸ìš”.

íšŒì˜ 3ë¬¸ë‹¨ ìš”ì•½:
{summary}
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ í•  ì¼ ì¶”ì¶œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# 7. ì„ì‹œ íŒŒì¼ ì •ë¦¬
def cleanup_segments(room_id: str):
    segment_dir = os.path.join(SEGMENT_BASE_DIR, room_id)
    if os.path.exists(segment_dir):
        shutil.rmtree(segment_dir) # íŒŒì¼ì„ í¬í•¨í•˜ëŠ” í´ë” ì‚­ì œ
        print(f"[ğŸ§¹] ì„ì‹œ ì˜¤ë””ì˜¤ ì¡°ê° ì‚­ì œ ì™„ë£Œ: {segment_dir}")

# ğŸ¯ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run_pipeline(audio_path: str, room_id: str):
    print("[ğŸš€] ì˜¤ë””ì˜¤ ë¶„í•  ì‹œì‘...")
    segment_dir = split_audio(audio_path, room_id)

    full_text = ""
    segments = sorted([os.path.join(segment_dir, f) for f in os.listdir(segment_dir)])
    for i, segment in enumerate(segments):
        print(f"[ğŸ”¤] í…ìŠ¤íŠ¸ ì „ì‚¬ ì¤‘: ({i+1}/{len(segments)})")
        transcript = transcribe_audio(segment)
        full_text += transcript + "\n"

    print("[ğŸ§ ] 3ë¬¸ë‹¨ ìš”ì•½ ì¶”ì¶œ ì¤‘...")
    summary = summarize_full_text(full_text)

    print("[ğŸ“Œ] ì£¼ìš” ë…¼ì˜ ì‚¬í•­ ì¶”ì¶œ ì¤‘...")
    discussion = summaries_discussion(summary)

    print("[ğŸ“] í•  ì¼ ëª©ë¡ ì¶”ì¶œ ì¤‘...")
    tasks = extract_tasks(summary)

    cleanup_segments(room_id)

    return {
        "transcript": full_text,
        "summary": summary,
        "tasks": tasks,
        "discussion": discussion,
        "roomId": room_id
    }
